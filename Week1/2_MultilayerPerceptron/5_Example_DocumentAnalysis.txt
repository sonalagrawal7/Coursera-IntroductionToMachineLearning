In the previous lesson, we introduced the concept of the multilayered perceptron, which in many ways is the most fundamental example of a neural network. Now, it is a relatively complicated and sophisticated model, it's a very powerful model, but there may be some confusion about how it works? Why it works? Why is this a good model? So, what we would like to do in this lesson, is to spend a little bit of time working through or talking through an example to try to give some intuition as to what we mean by these latent features and these latent processes, what does that mean? So, let's consider a relatively simple but important example. So, let's assume that our job is to analyze documents. So, here a document is just a set of words. So remember that x_i is a vector which represents a set of features for the ith data of interest. For us now in this example, what we mean is that x_i represents the features of document i, here in the context of document analysis. The simplest way that we can do this is just to count the words. So, assume that we're given a document, and let's assume that we have a vocabulary that is composed of V words, so the vocabulary size is V. What we're going to do to characterize a given document, here document i, is simply count the number of times each word appears in the document. Then what we're going to do is we're going to make a prediction based upon that feature vector. So, here prediction we're going to still limit ourselves to the binary case for simplicity. So, what we would like to do is given the document, and given the words in the document, we want to make a prediction about whether a given person will like the document or find it interesting or whether they will dislike it. So, in the binary case, what we'll say is, if they like it, the label will be, Y will be one. If they dislike it, Y will be equal to zero. So, we're given data for training, remember when we do learning, the first thing we have to assume is that we have data with which to learn. So, that data is used to teach the model or to teach the algorithm, and when we talk about learning, what we mean by learning, is learning the parameters of our model. So, in this case, we're going to assume that we have N documents represented by X_1, X_2 through X_N. These are feature vectors which simply represent the number of times in each case that each of the V words is manifested in the document and then we're also given labels Y_1 through Y_N, which represent whether the individual of interest liked or disliked the document. Our goal is to build a model such that if we're given a new vector x, for a new document that the person has never seen before, we want to make a prediction will they like it or not like it.