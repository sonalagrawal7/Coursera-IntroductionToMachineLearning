Now, the way that we're going to do this, is using a multilayer perceptron. So, just to remind you of how this works, so the multilayer perceptron is shown on the left. This is represented at the first layer, so we start at the bottom and work our way up. So, let's look at what's going on for the first layer. So, remember what we're going to do is logistic regression essentially K times. So, the data xi are the counts of words for the ith document and b1, b2, bK are templates with which we take the inner product between xi in each of those templates b1, b2, through bK. So, the question is, in the context of this example, what might b1 through bK represent? What might those templates mean? So, there might be some latent topics that are characteristic of the documents. So, remember, we get to see the words, and then there are latent processes in the data or here in the document that we don't explicitly get to see. But we understand documents, and the documents are usually about some subject. So, the way that we might think about this is that b1, which is the first filter, might be representative of words that are characteristic of a particular topic, for example, sports. So, therefore, in our vocabulary of v words, there might be a subset of words that have high likelihood of appearing when the subject is sports. So, what we would expect is that the template b1 or the filter b1, with which we take the inner product of the data, if that filter is characteristic of the latent topic, sports. We would expect that that template b1 will have high values for words that are characteristic of sports and would basically have zero values for components which correspond to words that have nothing to do with sports. As another example, b2, which corresponds to the second latent process may correspond to a topic corresponding to history. So, then in that case, we would expect that the template b2 would have high values for words that are associated with history and essentially zero values for words that have nothing to do with history. Then this can be done for each of the k latent topics and for example, the kth topic might be associated with politics. So, a way to think about this is, we're given a feature vector xi, which represents the counts of words in the document. We're going to take an inner product of xi with k filters or k templates. We can think of these as representing k latent processes. In the context of documents, we might think of these as topics, topics of sports, history, politics. So, the features that come out of the first layer of our model, represent given the words that we see in our feature vector, what is the probability that this document is about sports? What is the probability from zero to one, that this document is about history? What is the probability from zero to one that this document is about politics? Those are the k latent or can be thought of as the k latent processes or features that come out of the first layer of our model. So, now we go to the second layer. Now, we're going to do the same thing. We're going to take the outputs of the first layer which are represented as Sigma Zi, which represent the features that come out of the first layer Zi that then go through the Sigmoid function which turn it into a probability from zero to one. We play exactly the same game, we take those features and now multiply them by layer two filters, which we'll represent as C1, C2 through CJ. So, in this case, J filters that were manifesting. So, what do these filters represent? Well, these filters might emphasize certain features from layer one, and remember the features from layer one correspond to topics. So therefore, we could think of the filters C1 through CJ representing meta-topics, which means combinations of topics from layer one. So remember, the layer one topics correspond to things like sports, history, politics. The layer two filters, Z1 through CJ, are basically providing waiting on the layer one features. So, for example, the template C1 may have high strength for the features at layer one that correspond to the topics from sports and the topic from history. So therefore, if the output of the template or filter C1 is large, that implies that the document is about a combination of sports and history, in other words the history of sports. If C2 for example, might emphasize the features from layer one that are associated with politics and also sports. So, these meta-topics, which means combination of topics C2 for example, might represent how politics is connected to sports. So therefore, if the document is about politics and sports, we would expect that when we take the inner product at layer two with C2, the output will be high. So, this is done for each of the filters C1 through CJ. So, again to think about this, the data x, which in this case is a count of words at layer one, the filters b1 through bK are looking for topics, in other words, sets of words that are associated with certain topics. At layer two the filters C1 through CJ are looking for meta-topics, which means combinations of topics. Then finally, when we get to the top, this logistic regression at the top, what we're doing is we're making a decision and we're asking the question, given the meta-topics that seemed to be apparent characteristic of the latent features at layer two, what is the probability that the person of interest is going to like the document or not? So, again if we look at what this layer two meta-topics represent, if a person is interested in the history of sports, then we would expect that if the filters Z1, when we take the inner product of the features Sigma Zi with filters C1, if C1 is characteristic of sports and history, and if the person of interests likes the history of sports, then we would expect that the filter at layer three D, that filter D would look for the situation in which meta-topics associated with the history of sports was high. So, in this way, we manifest a deep architecture which has an intuitive meaning of what these latent features represent. Now, this is a relatively simple example chosen specifically to try to give some intuition. It's not always the case that the latent features are easily interpreted, but this hopefully gives you some intuition as to why a deep learning model might work well and captures aspects, latent aspects of the data that we're interested in