So, now let's based upon using that even further intuition, let's ask the question, how well does this technology perform on real data at massive scale? So, recall that one of the significant developments in deep learning occurred around 2013, which was the bringing together of the convolutional neural network which was our fundamental model, which actually was developed around 1989: computational power, the graphical processor unit, and massive data at scale. So, what you see here are many many images, reflective of what's called the ImageNet Dataset. This corresponds to classifying a thousand different types of images, a thousand classes. So, remember when we were talking about the labels of the images, we were talking about binary labels, plus one, minus one. We introduced that purely for simplicity. We are now using with this deep convolutional neural network architecture. At the top of the network, we're making a classification to 1,000 different classes. So, significantly more than binary. For the training data, and remember that one of the key things that made Neuro Networks work so well, was massive quantities of data. So, there was roughly 1,000 example training images for each of the 1,000 image classes, and consequently about one million or actually 1.2 million training images. To give you an example of what some of these images look like, three of them are shown at the bottom left. So, the thing to take away for this figure is, we look at the bottom left. These are real images. These are sophisticated images, and we're going to use these deep convolutional neural networks to classify them. The image to the right is simply to depict massive quantities of data. So, now how well does this technology work? So, the technology was developed as I said, around 2013. This is the performance of these models as a function of time. So, these are the best performing algorithms as a function of time. So, the 2010 and 2011, that is technology that preceded the convolutional neural net. Then, around 2012 to 2013 is when the convolutional neural network came to the forefront. You could see that there was a significant improvement in performance. This is the classification accuracy, the vertical axis represents classification accuracy, and the horizontal line at five percent is representative of performance of humans. So, we could see that as the years have moved from 2012 to 2013 to 2017, we are now at a point where these deep convolutional neural network architectures are providing performance that is better than that of humans. So, now to give you a sense of other things that we could do with this architecture. So, these are eight example images, and this is an example of how the model works. So, recall that there are a 1,000 different labels, and the model provides a probability of which label is associated with the image under test. So, what you're seeing here is, in each case you see the image under test, and then beneath that you see the probabilities from the model of what the model thinks the image is representative of. So, you could see that in each example, the bar represents probability. So, what we're listing is, for each image on the top, beneath it we're depicting the five most probable labels that correspond to that image. So, if you look at each of these, and these are representative examples, the performance is quite impressive. So, the takeaway from this is that, first the images are of significant realism, and complexity. Secondly, the performance of the model is truly extraordinary. When we look at this relative to the performance of humans, the ability of humans to do this labeling process is actually and currently inferior to the performance of these deep neural network architectures. Another key breakthrough that I talked about in the history of the Deep Architecture occurred recently, was in the context of Go. So, Go is a very famous game that is played largely in Asia. The Go board which is depicted here is significantly more complicated than a game such as chess. This game Go is almost a religious game in places like South Korea. There are people in South Korea who are essentially professional Go players in their schools for learning how to play Go. The game Go, which is a two-player game, was believed to be so sophisticated and so challenging that there was no way that a machine or an algorithm of the sort that we have looked at could defeat a human. So, recently, DeepMind who is based in the UK, they developed an algorithm which at its heart, was based upon the deep convolutional neural network technology that we have discussed at length. They built an algorithm that could take a picture of the Go board, send that picture into a deep convolutional neural network. Then, based upon what the algorithm saw in the image of the Go board, it would recommend the best next move for the machine to take. So, DeepMind developed this technology, it worked well. They ultimately did a match between the machine, which essentially is based upon a deep convolutional neural network, and some additional technology which is put on the top of that, which is called reinforcement learning. But the heart of it was actually the convolutional neural network. That algorithm or that machine, played some of the finest Go players in the world. Many of them from Asia, and as I mentioned, these are essentially professional Go players. Something occurred that previously people thought was inconceivable. That was that this deep machine learning technology, beat the very finest Go players in the world. This was a very very significant milestone. It represented the fact that this deep learning technology had truly matured to the point where it could do things that previously people thought were impossible. Other things that have been done, digit recognition. These deep architectures have been used to do other things such as recognizing images that correspond to human, writing a significant challenge. Another thing that has been done just to give again a sense of the sophistication of the technology. So, here are six images, each of which was analyzed by the convolutional neural network architecture that we've discussed, deep convolutional network architecture. So, the algorithm took the image in and then send that through a deep neural network architecture. The features at the top of the architecture which were previously used for classification are here used to do something arguably even more challenging. So, given the features at the top of the neural network, those features were sent in to a natural language processing algorithm, which then synthesized text to describe the image. So, each of the captions that you see written here in English was manifested by a machine. So, what is going on here is the image goes in. That image is sent through a deep convolutional neural network. The features at the top of that deep convolutional network are then sent into a different Neuro Network, which is then used to synthesize text. So, if you look at the text, you notice that it's a very high quality, highly realistic, grammatically correct, also very well representative of what is happening in the image. So, this is an example of how modern machine learning is generating so much excitement. This is an integration of image analysis and text synthesis. If we recall back to a prior lesson, we talked about something called Long Short-Term Memory, which we will discuss in further detail elsewhere in this module. The text analysis, or the text synthesis that you see here is based upon the long short-term memory architecture.