So, now that we have an idea of what happens at each of these convolutional layers and at these pooling layers, let's review what it looks like to train such a network with gradient descent. So, we assume that we have a set of input images. Each of those input images has a respective ground truth label associated with it. So, for a binary classification task like diabetic retinopathy, you have a label of plus one for an unhealthy retina and a label minus one for a healthy retina. For each of those input images In, so the nth input image, we feed that input image through the convolutional neural network. The first thing that happens is there's a convolution operation that uses the filters of each of the convolutional elements, each of the features that we want to extract from an input image, we have first have layer one filter, so that's Phi one, two, through Phi K, if we have k different features we want to extract from that input image. Those are applied to the input image to result in a stack of feature maps via the convolution function, which is represented here as f. So, that function f takes in as input, the In, the nth input image, the convolutional filters and the output of that operation is Mn, the stack of feature maps. That convolutional operation happens again, but now with the layer two filters, here represented as Psi one, two through K, and the convolutional operation here f takes in as input Mn, the layer one feature maps and also the parameters of the layer two filters to give an output resulting stack of layer two feature maps Ln. That's repeated one more time. There's another convolutional function here. You see at the top, that takes in as input Ln, the layer two feature maps, the layer three filters, omega one, two through K results in the final layer three feature maps Gn. These feature maps are then transformed one more time via these fully connected layers, which we're representing here as a function script L that has a set of fully connected a weight matrix W. Those weights determine how the layer three feature maps, here Gn are transformed to result in the predicted label Ln for that input image In. So, each input image In via these operations results in a label prediction Ln. The whole idea is that we want to find the parameters that help match the predicted label to associate it with that input image to the ground truth label. The way that we do that is we set up some sort of loss function that compares how well the prediction matches the ground truth, that's typically something like the binary cross entropy function. We want to reduce and minimize the average loss across all of the input images In. So, that is that average loss is called the empirical risk function, which you see here on the right, that function e. That function, of course, is a function of all the layer one filters and the final fully connected weights in that classifier. The name of the game is to learn the layer one filter parameters, the layer two filter parameters, layer three filter parameters, and the final readout weights in those fully-connected layers that minimize this loss function. In doing so, you've now developed a system that can take in an input image and then correctly predict whether or not it has diabetic retinopathy. So typically, this empirical risk function can be quite complicated, and it exists in this very high-dimensional space and the way that we find the best fit parameters to reduce this loss function and best predict what's in these images, you need to use this thing called gradient descent. Gradient descent is this strategy in which you make a point estimate of the slope, the multidimensional slope or the gradient of this empirical risk function for a given set of parameters. Here, we're just encapsulating the entire set of parameters, these layer one, layer two, layer three filters in the fully-connected weights as one single theta parameter. So, but imagine you have a value for each of those weights in the filters and then the readout weights. We can get at that point, for those values of parameters in the risk function. We can now get the slope, the multidimensional slope of that risk function. Based on that slope, we can take a step with size alpha here in the gradient descent equation that can bring us closer to the minimum. So, that's what's showing here on the graph on the left. So, imagine for some values of parameters, look at this positive slope points for some initial starting point for our parameters that puts us at that region of the risk function. We calculate the slope. It's positive slope, so then we reverse the sign of that because we want to walk downwards to find the minimum and then we take a step size here denoted by that black arrow. Multiplying now that step size by the negative of the slope, we update our parameters and that moves us down the hill to that next red spot. We continue that process until we reach a green spot, the nearest local minimum in our function. You see on the left another alternative. We had started with the parameter values on the left underneath that word negative slope, we'd have also followed the gradient down to that local minimum. So in practice, to calculate that gradient, we don't actually feed in all the input images which will be required to get the actual slope of the entire risk function, instead we use this thing called Stochastic gradient descent, where we make an estimate of the value of the risk function of the gradient to the risk function by taking a random subset of the data and getting the gradient with respect to the current parameter values for that random subset of data, the corresponding value of that risk function, and then we just update the parameters using those gradients from that random subset rather than the entire set of data. In practice, that leads us to very similar solutions at a much faster rate than trying to calculate gradient descent across the entire input data set.