What is the advantage of having this hierarchical representation of image features where the convolutional neural network extracts in sequence? One big advantage is that by learning and sharing statistical similarities within the high level pieces of the image, within these high level motifs, we better leverage all the training data. What does that mean? That means that if you're doing let's say, building an eminence classification system where you want to distinguish nine from seven, because the nine has low-level elements that the seven also has, you can learn a little bit about the building blocks of a nine from looking at the seven, right? So, across the entire training set, you can learn a lot from the other examples to help you classify the example of interests. So, that's very powerful. Related point is that if you're trying to learn some high-level filter on its own, and reinventing the wheel every single time, right? So, having a high-level seven feature, high-level nine feature, you don't want when you bring in a new class that you might want to classify, you don't get to use what you've learned about the low-level features to aid you in building up a representation to help you identify and classify that new class. That's a particularly powerful feature of the convolutional neural network. So, being able to leverage what the network has learned at lower levels, bring that information up to a new particular application of the network, okay? So, what this is called is transfer learning, and so I just want to go over this. So, in transfer learning, you take a network that's already been trained on a previous large database classification task. So, the ImageNet competition for instance. Then, you do additional training in the domain of interests. So, for that diabetic retinopathy case, what happens is, in the training neural network is that you take in an input image of retina. Okay, that retina is image is digested and features are extracted throughout all the layers in the network, and then there's a classification decision at the top, but whether or not the retina is healthy or diseased. It turns out that in this paper and most papers of this kind, they use pre-initialized weights from a network that have been trained on the ImageNet dataset, most drastically increases and improves performance. The reason why is that the top-level features, sometimes just in the classifier, those fully-connected layers, those are the ones that are highly specialized for particular task, right? For a particular domain, but the low-level features, right? These layer with these elementary building blocks are universal to all images. So, once you've learned them from a large data set, you don't need to necessarily learn them again because the retina image has low-level building blocks, are also reused in images of cats and of cars, et cetera. So, you can speed up the entire training process by reusing a network, by transferring one another network has learned on a different image classification task to the classification task of interest. That's called transfer learning. Right. So, just to hammer this point home, so the low-level features are universal to all images. So, on the left, I want to show you layer when filters from a convolutional neural network. So, these are little edge detectors that are extracting edges at different orientations. Okay? You see very similar receptive fields or image features that activates single neurons in a real monkey visual cortex here on the right. Okay, so a real mammalian visual system is also extracting these low-level patterns to build up its own representation to build up a perception of the real world in a biological brain. Okay, so there's something very elemental and fundamental about these particular low-level feature extractors as you can see here, and that is the principle that's exploited by this transfer learning process.