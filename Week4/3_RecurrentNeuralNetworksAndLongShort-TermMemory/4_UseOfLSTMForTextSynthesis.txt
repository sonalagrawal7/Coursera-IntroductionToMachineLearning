So, now that we have introduced this concept of long short-term memory, or the LSTM, it'd be worthwhile to spend a few moments to understand how this model is used in text synthesis and as has been discussed, this basic framework for texts synthesis has achieved remarkable results across multiple applications. One is text translation from language A to language B, another application is in the automatic captioning of images. So, the idea would be that you're given an image, and then the machine can automatically look at the image or analyze the image and then synthesize text that is improper language, that can describe the image. So, we're going to talk a little bit about that in this lesson. So, let's assume that we have learned the LSTM parameters based upon a large document corpus, a large set of documents. So, how can we use the LSTM to synthesize text? So, remember that the basic construct is a neural network which has as input the hidden units H, and the memory cell C. From the previous step, those are inputs. The previous word is an input, and then out comes the next hidden unit which predicts the next word, and then we also update the memory cell and then the updated memory cell and the updated hidden units go to the next neuron network. So, the way that we are going to do this is that we're going to repeatedly apply, or in a recurrent manner apply this basic construct, and this is of course why it's called a recurrent neural network. This BOS symbol that I'm showing here, that means beginning of sentence. So, whenever we initialize the process of synthesizing text, we tell the model through the symbol BOS that we're beginning the sentence. So, it understands we're at the beginning, and then the model will automatically end the sentence through an EOS, or end of sentence symbol. So, we have a beginning of sentence symbol and an end of sentence symbol EOS. Each of which are represented by vectors, which are also learned those vectors are analogous, or basically they play the same role as the word vectors that we've talked about previously. Then, the hidden units are sent through a softmax, and then through that softmax, remember we get a probability on the next word. So, in this case the first word w_1. The softmax tells us the probability of which word is first. So, what we could do is we can select that word which is most likely as manifested by the softmax, and then we'll say that that word is w_1. The hidden units are updated to h_1, the memory cell is updated to c_1, that then goes into the next network, the next LSTM network. What we do then is we take the word w_1, which we've already predicted, and we use it as the input to the next step in our recurrent neural network. So, we first predict the first word w_1, we then take the vector associated with w_1, and that is used as an input to the next neural network, the next layer in this recurrent process. Then the updated hidden unit h_2 is again sent through a softmax, we then again take the word that is most likely, that has the most highest probability out of the softmax, we call that w_2. W_2 is then sent down to be the input to the next layer. So, then we take the vector associated with w_2, we take h_1, we take c_1, we send it into our LSTM, and we do the same process. We get h_3 softmax, take the most likely word, that's w_3 and repeat. So, we can see that through this recurrent neural network, we can sequentially synthesize text. As I'll show in a moment, the quality of this synthesis is truly remarkable. Almost equivalent to what one might expect of a human. So, whenever we do this, we have to initialize the hidden units h_0 and c_0. So, typically, in real applications, we're going to initialize h_0 and c_0 to be consistent with some task, and so what I'm going to do is I'm going to give the example of the automatic captioning of a picture. So, let's look at this example. So, we see a picture of a bird, and we see some text that describes the bird. The thing I want you to recognize is that this text, this bird has read throat and breast, with a dark brown colored head and wings. That sentence was generated automatically by a machine. So, that sentence was not produced by a human, that sentence was produced by a machine. So, how how is this done? So, elsewhere in our lessons, we have learned about the deep convolutional neural network. The deep convolutional neural network is a framework by which we can analyze images such as this bird here. So, what is done is that the picture is first sent through a deep neural network, and then it manifests at the top of that neural network. It manifests a set of features which are characteristic of the image. Those features are then used to initialize the parameters of our long short-term memory. So, they initialize the memory cell c_0. That initialized memory cell c_0 is then sent through a long short term memory to synthesize a sentence which I showed you before. So, this is a so-called end to end method by which we can train a model to analyze images and then synthesize text simultaneously by taking two of the key components that we have discussed in our lectures. The deep convolutional neural network for analysis of images is used to extract features which predict the initialization of LSTM. With that initialization, the LSTM then synthesizes texts. So, the input is the image, the output is the text, and so to learn a model like this which is a combination of a deep convolutional neural network and a long short-term memory, recurrent neural network, what we do is we give the model examples of inputs, of images, and outputs of texts that were generated by humans, we have many examples of images and text, and then we use that data to learn the parameters of our convolutional neural network in our LSTM. Here are some examples that you can look at. Each of these are manifested by the machine. So, what is shown here are six examples of images, and then the text underneath that was generated automatically through the long short-term memory machine. So, if you look at these, it's remarkable I think, that the quality of the sentence is excellent, grammatically correct, and also if you look at the photograph, and if you'd look at the sentence, it's remarkable. I believe it is remarkable. The machine's ability to analyze the image and then to represent that image in English words that are meaningful, and also written in a way that is almost indistinguishable from what a human might do. This example now brings together two of the key concepts that we have discussed in these lectures that are driving some of the tremendous excitement in the opportunities for machine learning. We're taking the deep convolutional neural network for analysis of images in the LSTM, which is a state of the art method for synthesizing text. We're bringing these together to automatically caption images with a degree of accuracy and realism that is comparable to what a human might do.