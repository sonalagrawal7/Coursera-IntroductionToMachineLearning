{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "\n",
    "## 4.  Lesson 1\n",
    "\n",
    "#### Question 1\n",
    "What analogy highlights the purpose of word vectors?\n",
    "\n",
    "Two places near each other on a map are likely to have similar characteristics.\n",
    "\n",
    "\n",
    "#### Question 2\n",
    "What dimension is a typical word vector?\n",
    "\n",
    "More than two dimensions\n",
    "\n",
    "\n",
    "#### Question 3\n",
    "The result of convolving K filters with a text is N K-dimensional vectors. What is the result of a max pooling step?\n",
    "\n",
    "A K-dimensional vector\n",
    "\n",
    "\n",
    "#### Question 4\n",
    "In the example shown, what would be done after the max pooling step?\n",
    "\n",
    "Use existing methods to make a classification decision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representative example NLP problem: Sentiment Analysis\n",
    "\n",
    "## 5. Lesson 2\n",
    "\n",
    "#### Question 1\n",
    "Which model is used in the example?\n",
    "\n",
    "Multilayer perceptron\n",
    "\n",
    "\n",
    "#### Question 2\n",
    "What is the softmax function?\n",
    "\n",
    "A generalization of the logistic function.\n",
    "\n",
    "\n",
    "#### Question 3\n",
    "When does the softmax function reduce to the logistic function?\n",
    "\n",
    "When V = 2\n",
    "\n",
    "\n",
    "#### Question 4\n",
    "What is the goal of both of CBOW and Skip-Gram?\n",
    "\n",
    "To learn the model parameters from large corpus of text without human labeling.\n",
    "\n",
    "\n",
    "#### Question 5\n",
    "What function is being maximized to learn the parameters of the model?\n",
    "\n",
    "The sum of the logs of probabilities for each word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks and Long Short-Term Memory\n",
    "\n",
    "## 5. Lesson 3\n",
    "\n",
    "\n",
    "#### Question 1\n",
    "What two entities are concatenated and sent into a neural network?\n",
    "\n",
    "The vector associated with the previous word and the hidden vector of the previous network\n",
    "\n",
    "\n",
    "#### Question 2\n",
    "How many control neural networks are used in LSTM?\n",
    "\n",
    "3\n",
    "\n",
    "\n",
    "#### Question 3\n",
    "Which of the following best describes what the f_n neural network does?\n",
    "\n",
    "Controls the degree of “forgetting” of the old memory cell.\n",
    "\n",
    "\n",
    "#### Question 4\n",
    "In the example of figure captioning, how are the parameters of the LSTM model initialized?\n",
    "\n",
    "From the features at the top of a CNN that analyzed the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Natural Language Processing with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
