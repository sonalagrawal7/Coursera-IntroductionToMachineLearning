So far, we've talked about how we can define a network. This could be a simple network such as logistic regression or more complicated deep networks. We've also talked about how we can actually mathematically set up our learning goal. How do we actually want to define what our optimal parameters are? But one of the questions we still have left is how do we actually learn the network? We've set up a mathematical description, how do we learn from this mathematical description? So, learning itself is going to turn into an optimization problem. So, as a reminder, we want to find the parameters that minimize the average loss, and we can define our average loss here. We're saying our optimal parameters b are going to be the parameters that minimize our average loss, and this is going to be over all of our training data examples. So, we have our loss over our true values and our predicted values. So, how do we actually go through and find the parameters? We have this nice clear mathematical statement, but we want to understand how can we actually find the parameters that minimize this? How do we actually optimize b in order to minimize this function? So, in order to do this, I want to talk about gradient descent. Gradient descent is an incredibly famous mathematical optimization algorithm that has a long, long history. Instead of talking about it from a mathematical point of view, we want to talk about visually what's happening. So, our goal as a reminder is we have some mathematical function such as our average loss function that we want to minimize. The approach you'll want do is to try to find something that minimizes this function. So, I'm showing here on the right, I'm showing a simple one-dimensional function, and we want to find the parameter b. Here, it's a single parameter that minimizes this function. Now, everyone can see just by looking at this visualization that the minimum is at zero. But because this is a one-dimensional function, and we can just plot out the whole function. When we go to these very high dimensional and very complex functions, we're not going to be able to plot it out and just see where the minimum is, so we have to come up with an algorithm that can help us find the minimum. So, one approach we can take to do this is to start at a particular parameter value. Here we're starting at about 1.5, and we're showing here in this blue circle, and we have current point that's marking where we currently are. Often what we can do is instead of saying where the minimum is, we can say, "Well, at our current point we can figure out what the slope of our function is." So, we're showing here the slope of our function. Now, if we know we want to go to the direction that's going to help us find the minimum, we can just say, "Well, if we know our slope, what direction is pointing us down the hill?" So, at our current point we have our slope, and we say if we go to the right we're going to be going up the hill because that's what our slope is saying is going to happen, and if we go left we're going to go down the hill. So, we can actually do this by saying, "Well, if this is our current point, we can figure out what our slope is and our slope says, let's take a step to the left, because if we take a step to the left we're going to be able to get to the lower function value and actually start getting closer and closer to this minimum that we want, so our update is going to take a step to the left." So if we do that, we just visualize what happens, and we have a new current point. We've taken a step to the left, we have a new current point, we have a new slope. So after one update, we could say, "Well, we've taken one update now, we have a lower function value, we're not at the minimum yet, but we have a strategy that seems to be getting us closer and closer to the minimum." So, we can just repeat the exact same thing we did before. We can say, "Well, we know our current point, we know the slope of our current point, and it says once again, we want to take a step to the left." So, we can take a second update where we again take a step to the left. So after the second update, we can now say we've taken one step to the left and another step to the left. We now are getting closer and closer to the minimum, and we can once again calculate the slope. We can keep doing this, so this is after two updates, after three updates, we can see what's happening, and we get a little bit closer. We can repeat the same thing again, fourth update, and we just keep repeating this until we're satisfied. So, instead of talking about this visually, we can also talk about what this is doing mathematically. So if we have our function here, and we're saying we want to find the parameter that minimizes this function. So, what we're going to do if we're going to run with this gradient descent strategy is we're going to start at initial value. So, we're going to start at what we're going to call b superscript zero, and what we're going to do is we're going to keep running a series of updates, and this update is going to move us from b or kth value of b to a k plus oneth value of b. This can be, for example, for moving us from our zeroth update to our first update, and our zeroth update is where we start. So, we're going to iteratively run the procedure. So one, we're going to calculate the slope at the current point. For one parameter, this is going to be the derivative. This is just the name from calculus. For multiple parameters, this is going to be the gradient, and the gradient here is going to be denoted by this upside down triangle or upside down delta on our function. The gradient here is just going to mean a multi-dimensional slope. It just means we're going to take the slope in each one of our dimensions and we're going to use this to define the gradient of our function. We're going to move in the direction of the negative gradient with step size alpha k, and alpha k is going to be our step size on our kth iteration. We get to choose what it is. During the hands-on session, we'll talk about some strategies for choosing what this value alpha is going to be, but for now, we're just going to consider it a value that saying how much do we want to move in this direction and we're going to run our update. If we have this beta k, and we're going to move a little bit in the direction of the negative gradient. So if we're looking at our slope here, negative is going to be to the left, and so, this is just a mathematical description of this exact update we just did. We're just going to keep running wanted to until we're converged. So far, we've talked about gradient descent. Now, we need to talk about how to make this work when we have truly big data, and I'll come up in a following lecture.