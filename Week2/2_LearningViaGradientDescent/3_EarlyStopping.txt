So, we have just talked about Stochastic Gradient Descent, and we have previously talked about validation, and so far, we haven't talked about the combination of how you can do validation with our optimisation algorithms. But in practice we're often going to combine these, and we're going to combine these through a technique called as early stopping. The idea is that we want to run our validation during optimization, and so the idea is that if we want to maximize the generalization of the network, this is actually mismatched with our optimization goal. Our optimization goal says we want to do as well as possible on our training dataset, but in practice, we're not actually trying to maximize our training dataset performance, we're trying to maximize how well we do when we go out into the real world. So, this becomes a bit of an issue because Stochastic Gradient Descent is optimizing a mathematical goal that's mismatched with what we're actually trying to do, and so there's a question where can we actually validate the model while running the optimization loop to address this problem? So, the idea in early stopping is that we can check the validation loss as we go, and the idea is that we're going to run our training loop, where we're going to run Stochastic Gradient Descent, and we're going to estimate what are average losses on our training dataset, and every so often we're going to also estimate what the performance is on our validation dataset. So, we're not going to use the validation data set to do the optimisation, or get our gradients, but we're going to use the validation data set to estimate our real-world performance. The idea is that let's not optimize to convergence on our training goal, let's optimize until the validation loss stops improving. This is going to be good for two reasons: one, this is going to help save us computational cost, this algorithms can take a very long time to train on a computer, and we want to use the minimum amount of computation possible. The second and better reason is that it's actually going to perform better when we go out into the real world. And so what we're showing here on the right is that if you run this optimization algorithm, Stochastic Gradient Descent, we're going to keep improving our training losses as we run more and more iterations of Stochastic Gradient Descent, we're going to keep getting a little bit better over time. But our validation dataset is actually going to get slightly worse as we overfit more and more. So, we want to stop when our validation is minimum, not when our training loss is minimum, and so the best validation and generalization is going to happen in about the middle of this plot, and this is a widely used technique in the field that can help us save computation, and can also help us give the best-performing network possible.